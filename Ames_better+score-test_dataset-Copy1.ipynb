{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a function and save the transformed final test set using joblib, so that you do not have to run the function again and again\n",
    "import pandas as pd\n",
    "\n",
    "def file_read(fn):\n",
    "\tdf=pd.read_csv(fn)\n",
    "\treturn df\n",
    "\n",
    "def month_season():\n",
    "\timport calendar\n",
    "\t# from time import strptime\n",
    "\t# look_up = {'1': 'Jan', '2': 'Feb', '3': 'Mar', '4': 'Apr', '5': 'May','6': 'Jun', '7': 'Jul', '8': 'Aug', '9': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec'}\n",
    "\t# df['MoSold']=df['MoSold'].apply(lambda x: look_up[x])\n",
    "\tdf['MoSold']=df['MoSold'].apply(lambda x: calendar.month_abbr[x])\n",
    "\tdf['Season']=df['MoSold'].copy()\n",
    "\n",
    "def season_create():\n",
    "\tdf.loc[(df['MoSold']=='Jun') | (df['MoSold']=='Jul') | (df['MoSold']=='Aug'),'Season']='Summer'\n",
    "\tdf.loc[(df['MoSold']=='Mar') | (df['MoSold']=='Apr') | (df['MoSold']=='May'),'Season']= 'Spring'\n",
    "\tdf.loc[(df['MoSold']=='Sep') | (df['MoSold']=='Oct') | (df['MoSold']=='Nov'),'Season']='Autumn'\n",
    "\tdf.loc[(df['MoSold']=='Jan') | (df['MoSold']=='Feb') | (df['MoSold']=='Dec'),'Season']='Winter'\n",
    "\n",
    "def neighborhood_convert():\n",
    "\tdf.loc[(df['Neighborhood']=='IDOTRR')|(df['Neighborhood']=='MeadowV')|(df['Neighborhood']=='SWISU')|(df['Neighborhood']=='BrDale')|(df['Neighborhood']=='NPkVill')|(df['Neighborhood']=='Blueste')|(df['Neighborhood']=='Sawyer'),'Neighborhood']='g'  \n",
    "\tdf.loc[(df['Neighborhood']=='Blmngtn')|(df['Neighborhood']=='Mitchel')|(df['Neighborhood']=='BrkSide')|(df['Neighborhood']=='NWAmes'),'Neighborhood']='h' \n",
    "\tdf.loc[(df['Neighborhood']=='Veenker')|(df['Neighborhood']=='SawyerW')|(df['Neighborhood']=='ClearCr')|(df['Neighborhood']=='Edwards')|(df['Neighborhood']=='Gilbert')|(df['Neighborhood']=='NAmes')|(df['Neighborhood']=='Timber')|(df['Neighborhood']=='Crawfor'),'Neighborhood']='i' \n",
    "\tdf.loc[(df['Neighborhood']=='NoRidge')|(df['Neighborhood']=='NridgHt')|(df['Neighborhood']=='StoneBr')|(df['Neighborhood']=='OldTown')|(df['Neighborhood']=='Somerst')|(df['Neighborhood']=='CollgCr'),'Neighborhood']='j'\n",
    "\n",
    "def fill_missing_values():\n",
    "\tdf.GarageType = df.GarageType.fillna(\"missing\")\n",
    "\tdf.loc[df['MasVnrType']==\"None\", 'MasVnrType'] = \"missing\"\n",
    "\tdf.loc[df['GarageCars'].isnull(), 'GarageCars'] = 0\n",
    "\tdf.loc[df['TotalBsmtSF'].isnull(), 'TotalBsmtSF'] = 0\n",
    "\tdf.loc[df['GarageArea'].isnull(), 'GarageArea'] = 0    \n",
    "\tdf.loc[df['SaleType'].isnull(), 'SaleType'] = df['SaleType'].mode()[0]     \n",
    "\tdf.loc[df['KitchenQual'].isnull(), 'KitchenQual'] = \"missing\"   \n",
    "\tdf.loc[df['Functional'].isnull(), 'Functional'] = \"Typ\"   \n",
    "\tdf.loc[df['BsmtUnfSF'].isnull(), 'BsmtUnfSF'] = 0    \n",
    "\tdf.loc[df['BsmtFullBath'].isnull(), 'BsmtFullBath'] = 0   \n",
    "\tdf.loc[df['BsmtQual'].isnull(), 'BsmtQual'] = \"missing\"\n",
    "\tdf.loc[df['MasVnrType'].isnull(), 'MasVnrType'] = \"missing\"\n",
    "\tdf.GarageYrBlt = df.GarageYrBlt.fillna(df['GarageYrBlt'].median())\n",
    "\tdf['KitchenQual'] = df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])\n",
    "\tdf['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n",
    "\tdf['MSZoning'] = df['MSZoning'].fillna(df['MSZoning'].mode()[0])\n",
    "\n",
    "def find_age():\n",
    "\tdf['Age_building']=(df['YrSold']-df['YearBuilt'])\n",
    "\tdf['Since_remodeled']=(df['YrSold']-df['YearRemodAdd'])\n",
    "\tdf['Age_garage']=(df['YrSold']-df['GarageYrBlt'])\n",
    "\tdf['MoSold']=df['MoSold'].astype(str)\n",
    "\tdf['Season']=df['Season'].astype(str)\n",
    "\tdf['YrSold']=df['YrSold'].astype(str)\n",
    "\n",
    "\n",
    "def convert_garagetype(x, y, col_name):\n",
    "\tfor ele in range(len(x)):\n",
    "\t\tif x[ele]=='Detchd':\n",
    "\t\t\tif x[ele] in y:\n",
    "\t\t\t\tx[ele]=-y[x[ele]]\n",
    "\t\telse:\n",
    "\t\t\tif x[ele] in y:\n",
    "\t\t\t\tx[ele]=y[x[ele]]\n",
    "\tdf.drop(col_name, axis=1)\n",
    "\tdf[col_name]=pd.Series(x)\n",
    "\t    # return d[col_name].head()\n",
    "\n",
    "\n",
    "\n",
    "# def convert_MasVnrType(x, y, col_name):\n",
    "# \tfor ele in range(len(x)):\n",
    "# \t\tif x[ele]=='None':\n",
    "# \t\t\tif x[ele] in y:\n",
    "# \t\t\t\tx[ele]=-y[x[ele]]\n",
    "\t\n",
    "# \t\telse:\n",
    "# \t\t\tif x[ele] in y:\n",
    "# \t\t\t\tx[ele]=y[x[ele]]\n",
    "# \tdf.drop(col_name, axis=1)\n",
    "# \tdf[col_name]=pd.Series(x)\n",
    "# \t    # return d[col_name].head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_SaleCondition(x, y, col_name):\n",
    "\tfor ele in range(len(x)):\n",
    "\t\tif x[ele]=='Abnorml':\n",
    "\t\t\tif x[ele] in y:\n",
    "\t\t\t\tx[ele]=-y[x[ele]]\n",
    "\t\telse:\n",
    "\t\t\tif x[ele] in y:\n",
    "\t\t\t\tx[ele]=y[x[ele]]\n",
    "\tdf.drop(col_name, axis=1)\n",
    "\tdf[col_name]=pd.Series(x)\n",
    "    # return d[col_name].head()\n",
    "\n",
    "#If unfinished area in the basement is not zero then add negative sign\n",
    "def convert_BsmtUnfSF(x, col_name):\n",
    "\tfor ele in range(len(x)):\n",
    "\t\tif x[ele]!=0:\n",
    "\t\t\tx[ele]=-x[ele]\n",
    "\tdf.drop(col_name, axis=1)\n",
    "\tdf[col_name]=pd.Series(x)\n",
    "    # return d[col_name].head()\n",
    "\n",
    "def labelencoding_categorical_ordinal(x):\n",
    "\tfrom sklearn.preprocessing import LabelEncoder\n",
    "\tfor c in x:\n",
    "\t\tlbe = LabelEncoder() \n",
    "\t\tlbe.fit(list(df[c].values)) \n",
    "\t\tdf[c] = lbe.transform(list(df[c].values))\n",
    "\n",
    "\n",
    "# def convert_Functional(x, y, col_name):\n",
    "# \tfor ele in range(len(x)):\n",
    "# \t\tif (x[ele]=='Mod') | (x[ele]=='Maj1') | (x[ele]=='Maj2') | (x[ele]=='Sev'):\n",
    "# \t\t\tif x[ele] in y:\n",
    "# \t\t\t\tx[ele]=-y[x[ele]]\n",
    "# \t\telse:\n",
    "# \t\t\tif x[ele] in y:\n",
    "# \t\t\t\tx[ele]=y[x[ele]]        \n",
    "# \tdf.drop(col_name, axis=1)\n",
    "# \tdf[col_name]=pd.Series(x)\n",
    "#     # return d[col_name].head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def convert_categorical(x, y, col_name):\n",
    "# \tfor ele in range(len(x)):\n",
    "# \t\tif x[ele] in y:\n",
    "# \t\t\tx[ele]=y[x[ele]]\n",
    "# \tdf.drop(col_name, axis=1)\n",
    "# \tdf[col_name]=pd.Series(x)\n",
    "#     # return d[col_name].head()\n",
    "\n",
    "\n",
    "# def convert_yearsold(x, y, col_name):\n",
    "# \tfor ele in range(len(x)):\n",
    "# \t\tif x[ele] in y:\n",
    "# \t\t\tx[ele]=y[x[ele]]\n",
    "# \tdf.drop(col_name, axis=1)\n",
    "# \tdf[col_name]=pd.Series(x)\n",
    "#     # return d[col_name].head()\n",
    "\n",
    "\n",
    "def main_fn():\n",
    "\tmonth_season()\n",
    "\tseason_create()\n",
    "\tneighborhood_convert()\n",
    "\tfill_missing_values()\n",
    "\tfind_age()\n",
    "\tlabelencoding_categorical_ordinal(['BsmtQual', 'GarageCond','KitchenQual','Functional','YrSold', 'MoSold', 'Season'])\n",
    "   \n",
    "    \n",
    "#     \tconvert_categorical(df['Neighborhood'].tolist(), dict(df['Neighborhood'].value_counts()/len(df)), 'Neighborhood')\n",
    "# \tconvert_categorical(df['BldgType'].tolist(), dict(df['BldgType'].value_counts()/len(df)), 'BldgType')\n",
    "# \tconvert_categorical(df['SaleType'].tolist(), dict(df['SaleType'].value_counts()/len(df)), 'SaleType')\n",
    "# \tconvert_categorical(df['MSZoning'].tolist(), dict(df['MSZoning'].value_counts()/len(df)), 'MSZoning')\n",
    "#     df[]\n",
    "    \n",
    "# \tconvert_categorical(df['MoSold'].tolist(), dict(df['MoSold'].value_counts()/len(df)), 'MoSold')\n",
    "# \tconvert_categorical(df['Season'].tolist(), dict(df['Season'].value_counts()/len(df)), 'Season')\n",
    "# \tconvert_categorical(df['Electrical'].tolist(), dict(df['Electrical'].value_counts()/len(df)), 'Electrical')\n",
    "# \tconvert_categorical(df['KitchenQual'].tolist(), dict(df['KitchenQual'].value_counts()/len(df)), 'KitchenQual')\n",
    "# \tconvert_yearsold(df['YrSold'].tolist(), dict(df['YrSold'].value_counts()/len(df)), 'YrSold')\n",
    "# \tconvert_garagetype(df['GarageType'].tolist(), dict(df['GarageType'].value_counts()/len(df)), 'GarageType')\n",
    "# \tconvert_MasVnrType(df['MasVnrType'].tolist(), dict(df['MasVnrType'].value_counts()/len(df)), 'MasVnrType')\n",
    "# \tconvert_SaleCondition(df['SaleCondition'].tolist(), dict(df['SaleCondition'].value_counts()/len(df)), 'SaleCondition')\n",
    "# \tconvert_BsmtUnfSF(df['BsmtUnfSF'].tolist(), 'BsmtUnfSF')\n",
    "# \tconvert_Functional(df['Functional'].tolist(), dict(df['Functional'].value_counts()/len(df)), 'Functional')\n",
    "\n",
    "# \tconvert_categorical(df['HouseStyle'].tolist(), dict(df['HouseStyle'].value_counts()/len(df)), 'HouseStyle')\n",
    "# \tconvert_categorical(df['BsmtQual'].tolist(), dict(df['BsmtQual'].value_counts()/len(df)), 'BsmtQual')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\tcols = [col for col in df.columns if col in ['LotArea', 'Neighborhood', 'GarageCars','MasVnrType', 'BsmtQual', 'TotalBsmtSF', '1stFlrSF','2ndFlrSF', 'GrLivArea', 'FullBath', 'HalfBath', 'TotRmsAbvGrd','GarageType', 'GarageArea', 'WoodDeckSF', 'MoSold', 'SaleType','SaleCondition','Age_building', 'Since_remodeled', 'Age_garage', 'BldgType', 'MSZoning', 'Season', 'KitchenQual', 'BedroomAbvGr', 'Functional', 'BsmtUnfSF','BsmtFullBath', 'KitchenAbvGr','YrSold','SalePrice']]\n",
    "\tdf1 = df[cols]\n",
    "\t# print(df1.head())\n",
    "\treturn df1\n",
    "\t#print(df1.head())\n",
    "\n",
    "df=file_read('/Users/chidam/Desktop/housing_price_kaggle_test_set.csv')\n",
    "df_test_transform=main_fn()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_justid=pd.read_csv('/Users/chidam/Desktop/housing_price_kaggle_test_set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1461, 1462, 1463, ..., 2917, 2918, 2919])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID=df_justid.Id.values\n",
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testset_Ames_joblib']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(df_test_transform, 'testset_Ames_joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=joblib.load('testset_Ames_joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>Season</th>\n",
       "      <th>Age_building</th>\n",
       "      <th>Since_remodeled</th>\n",
       "      <th>Age_garage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RH</td>\n",
       "      <td>11622</td>\n",
       "      <td>i</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>missing</td>\n",
       "      <td>3</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>730.0</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL</td>\n",
       "      <td>14267</td>\n",
       "      <td>i</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>3</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>312.0</td>\n",
       "      <td>393</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RL</td>\n",
       "      <td>13830</td>\n",
       "      <td>i</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>missing</td>\n",
       "      <td>2</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>...</td>\n",
       "      <td>482.0</td>\n",
       "      <td>212</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL</td>\n",
       "      <td>9978</td>\n",
       "      <td>i</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>3</td>\n",
       "      <td>324.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>...</td>\n",
       "      <td>470.0</td>\n",
       "      <td>360</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RL</td>\n",
       "      <td>5005</td>\n",
       "      <td>j</td>\n",
       "      <td>TwnhsE</td>\n",
       "      <td>missing</td>\n",
       "      <td>2</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSZoning  LotArea Neighborhood BldgType MasVnrType  BsmtQual  BsmtUnfSF  \\\n",
       "0       RH    11622            i     1Fam    missing         3      270.0   \n",
       "1       RL    14267            i     1Fam    BrkFace         3      406.0   \n",
       "2       RL    13830            i     1Fam    missing         2      137.0   \n",
       "3       RL     9978            i     1Fam    BrkFace         3      324.0   \n",
       "4       RL     5005            j   TwnhsE    missing         2     1017.0   \n",
       "\n",
       "   TotalBsmtSF  1stFlrSF  2ndFlrSF    ...      GarageArea  WoodDeckSF  MoSold  \\\n",
       "0        882.0       896         0    ...           730.0         140       6   \n",
       "1       1329.0      1329         0    ...           312.0         393       6   \n",
       "2        928.0       928       701    ...           482.0         212       7   \n",
       "3        926.0       926       678    ...           470.0         360       6   \n",
       "4       1280.0      1280         0    ...           506.0           0       4   \n",
       "\n",
       "   YrSold  SaleType  SaleCondition  Season  Age_building  Since_remodeled  \\\n",
       "0       4        WD         Normal       2            49               49   \n",
       "1       4        WD         Normal       2            52               52   \n",
       "2       4        WD         Normal       1            13               12   \n",
       "3       4        WD         Normal       2            12               12   \n",
       "4       4        WD         Normal       3            18               18   \n",
       "\n",
       "  Age_garage  \n",
       "0       49.0  \n",
       "1       52.0  \n",
       "2       13.0  \n",
       "3       12.0  \n",
       "4       18.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skewed_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>4.074860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>3.112013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>2.128569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>1.556592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>1.129240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>0.918977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0.911944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0.841731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>0.804238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0.713993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.651195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_building</th>\n",
       "      <td>0.589056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>0.436174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Since_remodeled</th>\n",
       "      <td>0.399017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>0.295986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>0.295534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>0.168813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_garage</th>\n",
       "      <td>0.168137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <td>-0.101028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>-0.109880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>-0.208988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>-1.014791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenQual</th>\n",
       "      <td>-1.467326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functional</th>\n",
       "      <td>-3.983127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Skewed_features\n",
       "KitchenAbvGr            4.074860\n",
       "LotArea                 3.112013\n",
       "WoodDeckSF              2.128569\n",
       "1stFlrSF                1.556592\n",
       "GrLivArea               1.129240\n",
       "BsmtUnfSF               0.918977\n",
       "2ndFlrSF                0.911944\n",
       "TotRmsAbvGrd            0.841731\n",
       "TotalBsmtSF             0.804238\n",
       "HalfBath                0.713993\n",
       "BsmtFullBath            0.651195\n",
       "Age_building            0.589056\n",
       "BedroomAbvGr            0.436174\n",
       "Since_remodeled         0.399017\n",
       "GarageArea              0.295986\n",
       "FullBath                0.295534\n",
       "YrSold                  0.168813\n",
       "Age_garage              0.168137\n",
       "Season                 -0.101028\n",
       "GarageCars             -0.109880\n",
       "MoSold                 -0.208988\n",
       "BsmtQual               -1.014791\n",
       "KitchenQual            -1.467326\n",
       "Functional             -3.983127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import norm, skew\n",
    "numeric_feats = df_test.dtypes[df_test.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = df_test[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skewed_features' :skewed_feats})\n",
    "skewness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 skewed numerical features to transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['KitchenAbvGr', 'LotArea', 'WoodDeckSF', '1stFlrSF', 'GrLivArea',\n",
       "       'BsmtUnfSF', '2ndFlrSF', 'TotRmsAbvGrd', 'TotalBsmtSF', 'BsmtQual',\n",
       "       'KitchenQual', 'Functional'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = skewness[(abs(skewness) > 0.75).any(axis=1)]\n",
    "print(\"There are {} skewed numerical features to transform\".format(s1.shape[0]))\n",
    "s1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use the scipy function boxcox1p which computes the Box-Cox transformation of  1+x\n",
    "# Note that setting  λ=0 is equivalent to log1p used above for the target variable.\n",
    "# http://onlinestatbook.com/2/transformations/box-cox.html\n",
    "# https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.special.boxcox1p.html\n",
    "\n",
    "#So the idea is to convert only the features that are skewed more than 75% \n",
    "from scipy.special import boxcox1p\n",
    "skewed_index = s1.index\n",
    "lamb = 0.15#lamda\n",
    "for feature in skewed_index:\n",
    "    #all_data[feat] += 1\n",
    "    df_test[feature] = boxcox1p(df_test[feature], lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 64)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.get_dummies(df_test)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns[df_test.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import power_transform\n",
    "# X_test=power_transform(X, method='yeo-johnson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class stack_average_models(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, basemodels, metamodel, n_folds=5):\n",
    "        self.basemodels=basemodels\n",
    "        self.metamodel=metamodel\n",
    "        self.n_folds=n_folds\n",
    "#         print(self.basemodels)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        import numpy as np\n",
    "        self.basemodels_ = [list() for x in self.basemodels]\n",
    "        self.metamodel_ = clone(self.metamodel)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        holdout_predictions = np.zeros((X.shape[0], len(self.basemodels)))\n",
    "        for ind, model in enumerate(self.basemodels):\n",
    "            for train_ind, holdout_ind in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.basemodels_[ind].append(instance)\n",
    "                instance.fit(X[train_ind], y[train_ind])\n",
    "                y_pred = instance.predict(X[holdout_ind])\n",
    "                holdout_predictions[holdout_ind, ind] = y_pred\n",
    "                \n",
    "         \n",
    "        self.metamodel_.fit(holdout_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        import numpy as np\n",
    "        meta_features = np.column_stack([np.column_stack([model.predict(X) for model in basemodels]).mean(axis=1) for basemodels in self.basemodels_])\n",
    "        return self.metamodel_.predict(meta_features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get all the models with their appropriate parameters listed\n",
    "# Enet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.04, l1_ratio=0.9, random_state=3))\n",
    "\n",
    "# Krr = KernelRidge(alpha=0.0004, kernel='polynomial', degree=4, coef0=2.5)\n",
    "\n",
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.5, random_state=1))\n",
    "\n",
    "# Gboost=GradientBoostingRegressor(learning_rate=0.05, max_depth=4, min_samples_leaf=15, min_samples_split=8, n_estimators=3000, loss='huber', max_features='sqrt')\n",
    "\n",
    "# Xgboost=xgb.XGBRegressor(objective='reg:linear',silent=True, nthread=-1, colsample_bytree= 0.4, gamma=0.5,learning_rate=0.05,max_depth=8,min_child_weight=5,n_estimators=3500,reg_alpha=0.9,reg_lambda=1.5,subsample=0.6)\n",
    "\n",
    "# lightgbm=lgb.LGBMRegressor(objective='regression', random_state=500, feature_fraction_seed=9, bagging_seed=9, bagging_fraction=0.6,bagging_freq=3,learning_rate=0.05,max_bin=70,max_depth=4,min_data_in_leaf=10,min_sum_hessian_in_leaf=8,n_estimators=750,num_leaves=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Gboost=GradientBoostingRegressor(learning_rate=0.05, max_depth=4, min_samples_leaf=15, min_samples_split=10, n_estimators=3000, loss='huber', max_features='sqrt')\n",
    "\n",
    "\n",
    "\n",
    "Xgboost=xgb.XGBRegressor(objective='reg:linear',silent=True, nthread=-1, colsample_bytree= 0.8, gamma=0.04,learning_rate=0.05,max_depth=4,min_child_weight=5,n_estimators=3500,reg_alpha=0.9,reg_lambda=0.6,subsample=0.6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lightgbm=lgb.LGBMRegressor(objective='regression', random_state=500, feature_fraction_seed=9, bagging_seed=9, bagging_fraction=0.8,bagging_freq=3,learning_rate=0.05,max_bin=50,max_depth=5,min_data_in_leaf=6,min_sum_hessian_in_leaf=14,n_estimators=1000,num_leaves=6)\n",
    "\n",
    "\n",
    "Krr = KernelRidge(alpha=0.3, kernel='polynomial', degree=3, coef0=2.5)\n",
    "\n",
    "\n",
    "Enet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=0.5, random_state=3))\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0003, random_state=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load \n",
    "from sklearn.externals import joblib\n",
    "meta_enet=joblib.load('stacked_meta_enet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_lasso=joblib.load('stacked_meta_lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_krr=joblib.load('stacked_meta_krr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_lasso2=joblib.load('stacked_meta_lasso2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=joblib.load('dataframe_Ames_stacking_finalimprove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[df_train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_train['SalePrice']=np.log1p(df_train['SalePrice'])\n",
    "y_train=df_train['SalePrice'].values\n",
    "df_train=df_train.drop('SalePrice', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, skew\n",
    "numeric_feats = df_train.dtypes[df_train.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = df_train[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "#print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skewed_features' :skewed_feats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "skew_train = skewness[(abs(skewness) > 0.75).any(axis=1)]\n",
    "skewed_index_train = skew_train.index\n",
    "lamb = 0.15#lamda\n",
    "for feature in skewed_index_train:\n",
    "    #all_data[feat] += 1\n",
    "    df_train[feature] = boxcox1p(df_train[feature], lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[df_train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=df_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import power_transform\n",
    "# X=df_train.values\n",
    "# # for feat in df_train_x.columns:\n",
    "# #     df_train_x[feat] = power_transform(df_train_x[feat], method='yeo-johnson')\n",
    "# X_train=power_transform(X, method='yeo-johnson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#meta_lasso: ((Gboost, Xgboost, lightgbm), metamodel = lasso)\n",
    "\n",
    "meta_lasso.fit(X_train, y_train)\n",
    "stacked_pred1 = np.expm1(meta_lasso.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0757580324552057\n"
     ]
    }
   ],
   "source": [
    "meta_lasso_pred = meta_lasso.predict(X_train)\n",
    "# print(rmsle(y_train, meta_lasso_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# krr, enet\n",
    "# Krr = KernelRidge(alpha=0.6, kernel='polynomial', degree=3, coef0=1.5)\n",
    "\n",
    "# Enet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.859995503651e-19 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "Krr.fit(X_train, y_train)\n",
    "# krr_train_pred = Krr.predict(X_train)\n",
    "krr_pred = np.expm1(Krr.predict(X_test))\n",
    "# print(rmsle(y_train, krr_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13921395731248237\n"
     ]
    }
   ],
   "source": [
    "#Enet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=3))\n",
    "\n",
    "Enet.fit(X_train, y_train)\n",
    "Enet_train_pred = Enet.predict(X_train)\n",
    "Enet_pred = np.expm1(Enet.predict(X_test))\n",
    "# print(rmsle(y_train, Enet_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ensemble1 = stacked_pred1*0.70 + krr_pred*0.07 + Enet_pred*0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submissionfeb24 = pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble1})\n",
    "df_submissionfeb24.to_csv(\"/Users/chidam/Desktop/Ames_feb24.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_enet: stack_average_models(basemodels = (Gboost, Xgboost, lightgbm), metamodel = Enet)\n",
    "meta_enet.fit(X_train, y_train)\n",
    "stacked_pred2 = np.expm1(meta_enet.predict(X_test))\n",
    "meta_enet_pred = meta_enet.predict(X_train)\n",
    "# print(rmsle(y_train, meta_enet_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso\n",
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.001, random_state=1))\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_train_pred = lasso.predict(X_train)\n",
    "lasso_pred = np.expm1(lasso.predict(X_test))\n",
    "# print(rmsle(y_train, lasso_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble2 = stacked_pred2*0.77 + krr_pred*0.07 + lasso_pred*0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The following has improved the score from You advanced 149 places on the leaderboard!\n",
    "#Your submission scored 0.15751, which is an improvement of your previous score of 0.16840. Great job!\n",
    "\n",
    "df_submissionfeb24_2= pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble2})\n",
    "df_submissionfeb24_2.to_csv(\"/Users/chidam/Desktop/Ames_feb27_2.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# from sklearn.metrics import log_loss\n",
    "\n",
    "# weight_split = StratifiedShuffleSplit(test_size=0.10, random_state=1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the following did not work, so for now going with the traintestsplit\n",
    "# for train_index, test_index in weight_split.split(X_train, y_train):\n",
    "#     train_x, train_y = X_train[train_index], y_train[train_index]\n",
    "#     test_x, test_y = X_train[test_index], y_train[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_train, y_train, test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "Gboost=GradientBoostingRegressor(learning_rate=0.05, max_depth=4, min_samples_leaf=15, min_samples_split=10, n_estimators=3000, loss='huber', max_features='sqrt')\n",
    "Gboost.fit(train_x, train_y)\n",
    "# clfs.append(Gboost.fit(train_x, train_y))\n",
    "predictions.append(Gboost.predict(test_x))\n",
    "\n",
    "\n",
    "Xgboost=xgb.XGBRegressor(objective='reg:linear',silent=True, nthread=-1, colsample_bytree= 0.6, gamma=0.05,learning_rate=0.05,max_depth=4,min_child_weight=5,n_estimators=2500,reg_alpha=0.4,reg_lambda=1.5,subsample=0.8)\n",
    "Xgboost.fit(train_x, train_y)\n",
    "predictions.append(Xgboost.predict(test_x))\n",
    "# clfs.append(Xgboost)\n",
    "\n",
    "lightgbm=lgb.LGBMRegressor(objective='regression', random_state=500, feature_fraction_seed=9, bagging_seed=9, bagging_fraction=1.0,bagging_freq=7,learning_rate=0.07,max_bin=70,max_depth=7,min_data_in_leaf=6,min_sum_hessian_in_leaf=8,n_estimators=750,num_leaves=6)\n",
    "lightgbm.fit(train_x, train_y)\n",
    "# clfs.append(lightgbm)\n",
    "predictions.append(lightgbm.predict(test_x))\n",
    "\n",
    "Krr = KernelRidge(alpha=0.6, kernel='polynomial', degree=3, coef0=1.5)\n",
    "Krr.fit(train_x, train_y)\n",
    "# clfs.append(Krr)\n",
    "predictions.append(Krr.predict(test_x))\n",
    "\n",
    "\n",
    "Enet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=3))\n",
    "Enet.fit(train_x, train_y)\n",
    "# clfs.append(Enet)\n",
    "predictions.append(Enet.predict(test_x))\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.001, random_state=1))\n",
    "lasso.fit(train_x, train_y)\n",
    "# clfs.append(lasso)\n",
    "predictions.append(lasso.predict(test_x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### finding the optimum weights\n",
    "def mse_func(weights):\n",
    "    # scipy minimize will pass the weights as a numpy array\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions):\n",
    "            final_prediction += weight*prediction\n",
    "    return mean_squared_error(test_y, final_prediction)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights: [0.         0.5        0.22100428 0.02817392 0.12969814 0.11978128]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "starting_values = [0.5]*len(predictions) # minimize need a starting value\n",
    "bounds = [(0,1)]*len(predictions) # weights are bound between 0 and 1\n",
    "res = minimize(mse_func, starting_values, bounds = bounds, method='SLSQP')\n",
    "print('Best Weights: {weights}'.format(weights = res['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_enet.fit(train_x, train_y)\n",
    "pred_meta_enet=meta_enet.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions1=[]\n",
    "predictions1.extend((pred_meta_enet, Krr.predict(test_x), lasso.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights: [0.76480655 0.04394475 0.18988542]\n"
     ]
    }
   ],
   "source": [
    "#The following calculates the optimum weights of meta_enet with krr and lasso\n",
    "def mse_func_enet(weights):\n",
    "    # scipy minimize will pass the weights as a numpy array\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions1):\n",
    "            final_prediction += weight*prediction\n",
    "    return mean_squared_error(test_y, final_prediction)\n",
    "\n",
    "starting_values = [0.5]*len(predictions1) # minimize need a starting value\n",
    "bounds = [(0,1)]*len(predictions1) # weights are bound between 0 and 1\n",
    "res = minimize(mse_func_enet, starting_values, bounds = bounds, method='SLSQP')\n",
    "print('Best Weights: {weights}'.format(weights = res['x']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stacked_meta_krr = stack_average_models(basemodels = (Gboost, Xgboost, lightgbm), metamodel = Krr)\n",
    "\n",
    "\n",
    "\n",
    "meta_krr.fit(train_x, train_y)\n",
    "pred_meta_krr=meta_krr.predict(test_x)#meta_krr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_metakrr=[]\n",
    "predictions_metakrr.extend((pred_meta_krr, Enet.predict(test_x), lasso.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights: [0.74530821 0.13002938 0.12333773]\n"
     ]
    }
   ],
   "source": [
    "#The following calculates the optimum weights of meta_krr with Enet and lasso as additive models to the stacked regressor models\n",
    "def mse_func_krr(weights):\n",
    "    # scipy minimize will pass the weights as a numpy array\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions_metakrr):\n",
    "            final_prediction += weight*prediction\n",
    "    return mean_squared_error(test_y, final_prediction)\n",
    "\n",
    "starting_values = [0.5]*len(predictions_metakrr) # minimize need a starting value\n",
    "bounds = [(0,1)]*len(predictions_metakrr) # weights are bound between 0 and 1\n",
    "res = minimize(mse_func_krr, starting_values, bounds = bounds, method='SLSQP')\n",
    "print('Best Weights: {weights}'.format(weights = res['x']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_krr.fit(X_train, y_train)\n",
    "stacked3 = np.expm1(meta_krr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This did not improve the score\n",
    "ensemble3 = stacked3*0.76 + Enet_pred*0.13 + lasso_pred*0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submissionfeb24_3= pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble3})\n",
    "df_submissionfeb24_3.to_csv(\"/Users/chidam/Desktop/Ames_feb24_3.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This did not improve the score either\n",
    "ensemble34 = stacked3*0.85 + Enet_pred*0.13 + lasso_pred*0.12\n",
    "df_submissionfeb24_34= pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble34})\n",
    "df_submissionfeb24_34.to_csv(\"/Users/chidam/Desktop/Ames_feb24_34.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 2.329961151736817e-18 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.3470382470596302e-18 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.4314267042307028e-18 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 2.012482532610967e-18 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.4241543972281241e-18 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "predictions_lasso2=[]\n",
    "\n",
    "\n",
    "meta_lasso2.fit(train_x, train_y)\n",
    "pred_meta_lasso2=meta_lasso2.predict(test_x)\n",
    "predictions_lasso2.append(pred_meta_lasso2)\n",
    "\n",
    "\n",
    "Xgboost=xgb.XGBRegressor(objective='reg:linear',silent=True, nthread=-1, colsample_bytree= 0.8, gamma=0.04,learning_rate=0.05,max_depth=4,min_child_weight=5,n_estimators=3500,reg_alpha=0.9,reg_lambda=0.6,subsample=0.6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lightgbm=lgb.LGBMRegressor(objective='regression', random_state=500, feature_fraction_seed=9, bagging_seed=9, bagging_fraction=0.8,bagging_freq=3,learning_rate=0.05,max_bin=50,max_depth=5,min_data_in_leaf=6,min_sum_hessian_in_leaf=14,n_estimators=1000,num_leaves=6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Xgboost=xgb.XGBRegressor(objective='reg:linear',silent=True, nthread=-1, colsample_bytree= 0.6, gamma=0.05,learning_rate=0.05,max_depth=4,min_child_weight=5,n_estimators=2500,reg_alpha=0.4,reg_lambda=1.5,subsample=0.8)\n",
    "Xgboost.fit(train_x, train_y)\n",
    "predictions_lasso2.append(Xgboost.predict(test_x))\n",
    "# clfs.append(Xgboost)\n",
    "\n",
    "# lightgbm=lgb.LGBMRegressor(objective='regression', random_state=500, feature_fraction_seed=9, bagging_seed=9, bagging_fraction=1.0,bagging_freq=7,learning_rate=0.07,max_bin=70,max_depth=7,min_data_in_leaf=6,min_sum_hessian_in_leaf=8,n_estimators=750,num_leaves=6)\n",
    "lightgbm.fit(train_x, train_y)\n",
    "# clfs.append(lightgbm)\n",
    "predictions_lasso2.append(lightgbm.predict(test_x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights: [0.49947562 0.5        0.        ]\n"
     ]
    }
   ],
   "source": [
    "### finding the optimum weights\n",
    "\n",
    "# def mse_func_lasso2(weights):\n",
    "#     # scipy minimize will pass the weights as a numpy array\n",
    "#     final_prediction = 0\n",
    "#     for weight, prediction in zip(weights, predictions_lasso2):\n",
    "#             final_prediction += weight*prediction\n",
    "#     return mean_squared_error(test_y, final_prediction)\n",
    "\n",
    "\n",
    "#The following calculates the optimum weights of meta_krr with Enet and lasso as additive models to the stacked regressor models\n",
    "from scipy.optimize import minimize\n",
    "def mse_func_lasso2(weights):\n",
    "    # scipy minimize will pass the weights as a numpy array\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions_lasso2):\n",
    "            final_prediction += weight*prediction\n",
    "    return mean_squared_error(test_y, final_prediction)\n",
    "\n",
    "starting_values = [0.5]*len(predictions_lasso2) # minimize need a starting value\n",
    "bounds = [(0,1)]*len(predictions_lasso2) # weights are bound between 0 and 1\n",
    "res = minimize(mse_func_lasso2, starting_values, bounds = bounds, method='SLSQP')\n",
    "print('Best Weights: {weights}'.format(weights = res['x']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.557905972493588e-19 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 3.9323240401507523e-19 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 5.80081795097739e-19 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 3.861830385018916e-19 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Users/chidam/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 3.2712410540414983e-19 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#meta_lasso2 stacked_meta_lasso2 = stack_average_models(basemodels = (Gboost, Krr, Enet),metamodel = lasso)\n",
    "meta_lasso2.fit(X_train, y_train)\n",
    "stacked_pred4 = np.expm1(meta_lasso2.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Xgboost\n",
    "Xgboost.fit(X_train, y_train)\n",
    "Xgboost_pred = np.expm1(Xgboost.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lightgbm\n",
    "\n",
    "lightgbm.fit(X_train, y_train)\n",
    "lightgbm_pred = np.expm1(lightgbm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble4 = stacked_pred4*0.25 +Xgboost_pred*0.5 + lightgbm_pred*0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submissionfeb26_4= pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble4})\n",
    "df_submissionfeb26_4.to_csv(\"/Users/chidam/Desktop/Ames_feb26_4.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble4_5 = stacked_pred4*0.7 +Xgboost_pred*0.5 + lightgbm_pred*0.25\n",
    "\n",
    "df_submissionfeb26_5= pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble4_5})\n",
    "df_submissionfeb26_5.to_csv(\"/Users/chidam/Desktop/Ames_feb26_5.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This improved the score from that in the cell above\n",
    "ensemble4_6 = stacked_pred4*0.7 +Xgboost_pred*0.25 + lightgbm_pred*0.25\n",
    "\n",
    "df_submissionfeb26_6= pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble4_6})\n",
    "df_submissionfeb26_6.to_csv(\"/Users/chidam/Desktop/Ames_feb26_6.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble4_7 = stacked_pred4*0.85 +Xgboost_pred*0.05 + lightgbm_pred*0.05\n",
    "\n",
    "df_submissionfeb26_7= pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble4_7})\n",
    "df_submissionfeb26_7.to_csv(\"/Users/chidam/Desktop/Ames_feb26_7.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#You advanced 5 places on the leaderboard!Your submission scored 0.15724, which is an improvement of your previous score of 0.15751. Great job!\n",
    "ensemble4_8 = stacked_pred4*0.70 +Xgboost_pred*0.15 + lightgbm_pred*0.15\n",
    "\n",
    "df_submissionfeb26_8= pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble4_8})\n",
    "df_submissionfeb26_8.to_csv(\"/Users/chidam/Desktop/Ames_feb26_8.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble27_1 = stacked_pred4*0.50 +Xgboost_pred*0.50 + lightgbm_pred*0\n",
    "\n",
    "df_submissionfeb27_1= pd.DataFrame({\"ID\" : ID, \"SalePrice\" : ensemble27_1})\n",
    "df_submissionfeb27_1.to_csv(\"/Users/chidam/Desktop/Ames_feb27_1.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
